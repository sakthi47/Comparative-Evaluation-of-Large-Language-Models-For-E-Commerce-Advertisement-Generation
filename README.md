# 🚀 Comparative Evaluation of LLMs for E-Commerce Advertising  


## 🔍 What This Project is About
Can **AI-generated ads** (using GPT-4, Claude, Gemini, Deepseek) be as effective as human-made ones?  
This project benchmarks **Large Language Models (LLMs)** for **ad copy + image generation** and compares them to human ads through a **survey-based analysis**.  

---

## 🎯 Key Highlights
✨ **13 ad variants tested** across 5 product categories  
✨ **4 ad modes**: Human | AI Copy | AI Image | AI Copy+Image  
✨ **Survey ratings** on: Purchase Intent, Visual Appeal, Value, Clarity, Trust  
✨ **Statistical Analysis**: Welch ANOVA, η² effect size  
✨ **Result:** 📊 *AI ads performed on par with human ads — with more consistency*  

---

## 📊 Main Findings
- ✅ **Parity with Humans** → No significant difference → AI ads are perceived equally effective.  
- 🎨 **Visual Advantage** → AI ads scored higher on polish & appeal.  
- 📈 **Claude** slightly outperformed others in persuasion & trust.  
- 🤝 **Implication** → AI can safely augment human creatives, saving cost & time.  

---

## 🛠️ Tech & Tools
- **LLMs**: GPT-4 Turbo, Claude 3 Opus, Gemini 1.5, Deepseek  
- **Image Models**: DALL·E 3, Imagen 2, Stable Diffusion  
- **Survey Platform**: Qualtrics  
- **Analysis**: Python (Pandas, NumPy), Jupyter, Welch ANOVA  

---
