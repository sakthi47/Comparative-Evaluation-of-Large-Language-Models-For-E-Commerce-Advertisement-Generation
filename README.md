# ğŸš€ Comparative Evaluation of LLMs for E-Commerce Advertising  


## ğŸ” What This Project is About
Can **AI-generated ads** (using GPT-4, Claude, Gemini, Deepseek) be as effective as human-made ones?  
This project benchmarks **Large Language Models (LLMs)** for **ad copy + image generation** and compares them to human ads through a **survey-based analysis**.  

---

## ğŸ¯ Key Highlights
âœ¨ **13 ad variants tested** across 5 product categories  
âœ¨ **4 ad modes**: Human | AI Copy | AI Image | AI Copy+Image  
âœ¨ **Survey ratings** on: Purchase Intent, Visual Appeal, Value, Clarity, Trust  
âœ¨ **Statistical Analysis**: Welch ANOVA, Î·Â² effect size  
âœ¨ **Result:** ğŸ“Š *AI ads performed on par with human ads â€” with more consistency*  

---

## ğŸ“Š Main Findings
- âœ… **Parity with Humans** â†’ No significant difference â†’ AI ads are perceived equally effective.  
- ğŸ¨ **Visual Advantage** â†’ AI ads scored higher on polish & appeal.  
- ğŸ“ˆ **Claude** slightly outperformed others in persuasion & trust.  
- ğŸ¤ **Implication** â†’ AI can safely augment human creatives, saving cost & time.  

---

## ğŸ› ï¸ Tech & Tools
- **LLMs**: GPT-4 Turbo, Claude 3 Opus, Gemini 1.5, Deepseek  
- **Image Models**: DALLÂ·E 3, Imagen 2, Stable Diffusion  
- **Survey Platform**: Qualtrics  
- **Analysis**: Python (Pandas, NumPy), Jupyter, Welch ANOVA  

---
